{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f241165",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from numpy import prod\n",
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ebaa8a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "dga_domain_file = 'DGA_domains.csv'\n",
    "non_dga_domain_file = 'non_DGA_domains.csv'\n",
    "validation_dga_domain_file = 'validation_DGA_domains.csv'\n",
    "validation_non_dga_domain_file = 'validation_non_DGA_domains.csv'\n",
    "test_domains_file = 'test_domains.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a2403cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_gram_split = [2,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1febb844",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_domain_names_without_tld(df):\n",
    "    df = pd.DataFrame(df[0].str.split('.').apply(lambda s:s[0]))\n",
    "    df.columns = ['domain']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d951680",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read non_dga_domain_file\n",
    "df_non_dga = pd.read_csv(non_dga_domain_file, sep=',',header=None)\n",
    "df_non_dga = get_domain_names_without_tld(df_non_dga).drop_duplicates(keep='first')\n",
    "\n",
    "# Read dga_domain_file\n",
    "df_dga = pd.read_csv(dga_domain_file, sep=',',header=None)\n",
    "df_dga = get_domain_names_without_tld(df_dga).drop_duplicates(keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d328e433",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_domain_names_acc_to_ngram_param(df,n_gram_split):\n",
    "    # Get number of substrings for a particular split length\n",
    "    df['len'] = df['domain'].astype(str).map(len)\n",
    "    max_len = df['len'].max()\n",
    "    list_of_counts_of_various_ngrams = {}\n",
    "    for i in n_gram_split:\n",
    "        new_df = pd.DataFrame()\n",
    "        for j in range(0,max_len):\n",
    "            con = df['len'] >= i+j\n",
    "            new_df = new_df.append(pd.DataFrame(df.loc[con]['domain'].str[j:j+i]))\n",
    "        counts = new_df['domain'].value_counts().rename_axis('domains_substr').reset_index(name='counts')\n",
    "        list_of_counts_of_various_ngrams[i] = counts\n",
    "    return list_of_counts_of_various_ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a43c76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Generate n gram splits of domains for DGA and non DGA datasets\"\"\"\n",
    "list_of_counts_of_various_ngrams_non_dga = split_domain_names_acc_to_ngram_param(df_non_dga,n_gram_split)\n",
    "list_of_counts_of_various_ngrams_dga = split_domain_names_acc_to_ngram_param(df_dga,n_gram_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c63082c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500784\n"
     ]
    }
   ],
   "source": [
    "sum_of_all_substring_counts = 0\n",
    "for k,v in list_of_counts_of_various_ngrams_non_dga.items():\n",
    "    sum_of_all_substring_counts = sum_of_all_substring_counts + list_of_counts_of_various_ngrams_non_dga[k]['counts'].sum()\n",
    "for k,v in list_of_counts_of_various_ngrams_dga.items():\n",
    "    sum_of_all_substring_counts = sum_of_all_substring_counts + list_of_counts_of_various_ngrams_dga[k]['counts'].sum()\n",
    "print(sum_of_all_substring_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04dfa44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_substrings(domain,split):\n",
    "    sub_strs = []\n",
    "    for i in range(0,len(domain)-split+1):\n",
    "        sub_strs.append(domain[i:i+split])\n",
    "    return sub_strs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c2c5e3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def  get_score_from_training_dataset(training_data,sub_strs):\n",
    "#     print(training_data)\n",
    "    sub_str_scores = {}\n",
    "    sum_of_all_substring_counts = training_data['counts'].sum()\n",
    "    for sub_str in sub_strs:\n",
    "        if len(training_data.loc[training_data['domains_substr'] == sub_str]) != 0:\n",
    "            \n",
    "            count = training_data.loc[training_data['domains_substr'] == sub_str]['counts'].iloc[0]\n",
    "        else:\n",
    "            \n",
    "            count = 0\n",
    "        if sub_str in sub_str_scores:\n",
    "            sub_str_scores[sub_str] = sub_str_scores[sub_str] + count\n",
    "        else:\n",
    "            sub_str_scores[sub_str] = count\n",
    "    temp_scores = {}\n",
    "    for k, v in sub_str_scores.items():\n",
    "        if(v==0):\n",
    "            temp_scores[k] = 0\n",
    "        else:\n",
    "            temp_scores[k] = (v) / sum_of_all_substring_counts\n",
    "    \n",
    "    return temp_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c2b5f270",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.10</th>\n",
       "      <th>0.15</th>\n",
       "      <th>0.20</th>\n",
       "      <th>0.25</th>\n",
       "      <th>0.30</th>\n",
       "      <th>0.35</th>\n",
       "      <th>0.40</th>\n",
       "      <th>0.45</th>\n",
       "      <th>0.50</th>\n",
       "      <th>0.55</th>\n",
       "      <th>0.60</th>\n",
       "      <th>0.65</th>\n",
       "      <th>0.70</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>FPR</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.881188</td>\n",
       "      <td>0.465347</td>\n",
       "      <td>0.247525</td>\n",
       "      <td>0.138614</td>\n",
       "      <td>0.09901</td>\n",
       "      <td>0.059406</td>\n",
       "      <td>0.049505</td>\n",
       "      <td>0.039604</td>\n",
       "      <td>0.039604</td>\n",
       "      <td>0.009901</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FNR</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0.10      0.15      0.20      0.25      0.30     0.35      0.40  \\\n",
       "FPR   1.0  0.881188  0.465347  0.247525  0.138614  0.09901  0.059406   \n",
       "FNR   0.0  0.000000  0.000000  0.000000  0.000000  0.00000  0.047619   \n",
       "\n",
       "         0.45      0.50      0.55      0.60      0.65      0.70  \n",
       "FPR  0.049505  0.039604  0.039604  0.009901  0.000000  0.000000  \n",
       "FNR  0.047619  0.095238  0.238095  0.333333  0.428571  0.571429  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Determine threshold \"\"\"\n",
    "thresholds = [0.10,0.15,0.20,0.25,0.3,0.35,0.4,0.45,0.5,0.55,0.6,0.65,0.7]\n",
    "dict_of_thresholds_and_fpr_fnr = {}\n",
    "probability_list = []\n",
    "df_test = pd.read_csv(validation_non_dga_domain_file, sep=',',header=None)\n",
    "df_test = get_domain_names_without_tld(df_test).drop_duplicates(keep='first')\n",
    "count = 0\n",
    "# Split test domains into substrings\n",
    "for index, row in df_test.iterrows():\n",
    "    sum_scores_dga = 0\n",
    "    sum_scores_non_dga = 0\n",
    "\n",
    "    for split in n_gram_split:\n",
    "        sub_strs = get_substrings(row[\"domain\"],split)\n",
    "\n",
    "        # Get scores for substrings from non_dga training dataset\n",
    "        sub_str_scores_non_dga = get_score_from_training_dataset(list_of_counts_of_various_ngrams_non_dga[split],sub_strs)\n",
    "        scores_non_dga = list(sub_str_scores_non_dga.values())\n",
    "        sum_scores_non_dga = sum_scores_non_dga + sum(scores_non_dga)\n",
    "\n",
    "        # Get scores for substrings from dga training dataset\n",
    "        sub_str_scores_dga = get_score_from_training_dataset(list_of_counts_of_various_ngrams_dga[split],sub_strs)\n",
    "        scores_dga = list(sub_str_scores_dga.values())\n",
    "        sum_scores_dga = sum_scores_dga + sum(scores_dga)\n",
    "        \n",
    "    if (sum_scores_dga + sum_scores_non_dga) == 0:\n",
    "        print(row[\"domain\"] + \" origin is uncertain.\")\n",
    "    else:\n",
    "        p_dga = sum_scores_dga/(sum_scores_dga + sum_scores_non_dga)\n",
    "        p_non_dga = sum_scores_non_dga/(sum_scores_non_dga + sum_scores_dga)\n",
    "        probability_list.append([p_dga,p_non_dga])\n",
    "for threshold in thresholds:\n",
    "    p_array = np.array(probability_list)[:,0]\n",
    "    count = (p_array>threshold).sum()\n",
    "    fpr = count/len(df_test)\n",
    "    dict_of_thresholds_and_fpr_fnr[threshold] = [fpr,-1]\n",
    "        \n",
    "df_test = pd.read_csv(validation_dga_domain_file, sep=',',header=None)\n",
    "df_test = get_domain_names_without_tld(df_test).drop_duplicates(keep='first')\n",
    "probability_list = []\n",
    "count = 0\n",
    "# Split test domains into substrings\n",
    "for index, row in df_test.iterrows():\n",
    "    sum_scores_dga = 0\n",
    "    sum_scores_non_dga = 0\n",
    "\n",
    "    for split in n_gram_split:\n",
    "        sub_strs = get_substrings(row[\"domain\"],split)\n",
    "\n",
    "        # Get scores for substrings from non_dga training dataset\n",
    "        sub_str_scores_non_dga = get_score_from_training_dataset(list_of_counts_of_various_ngrams_non_dga[split],sub_strs)\n",
    "        scores_non_dga = list(sub_str_scores_non_dga.values())\n",
    "        sum_scores_non_dga = sum_scores_non_dga + sum(scores_non_dga)\n",
    "\n",
    "        # Get scores for substrings from dga training dataset\n",
    "        sub_str_scores_dga = get_score_from_training_dataset(list_of_counts_of_various_ngrams_dga[split],sub_strs)\n",
    "        scores_dga = list(sub_str_scores_dga.values())\n",
    "        sum_scores_dga = sum_scores_dga + sum(scores_dga)\n",
    "    if (sum_scores_dga + sum_scores_non_dga) == 0:\n",
    "        print(row[\"domain\"] + \" origin is uncertain.\")\n",
    "    else:\n",
    "        p_dga = sum_scores_dga/(sum_scores_dga + sum_scores_non_dga)\n",
    "        p_non_dga = sum_scores_non_dga/(sum_scores_non_dga + sum_scores_dga)\n",
    "        probability_list.append([p_dga,p_non_dga])\n",
    "for threshold in thresholds:\n",
    "    p_array = np.array(probability_list)[:,0]\n",
    "    count = (p_array<threshold).sum()\n",
    "    fnr = count/len(df_test)\n",
    "    dict_of_thresholds_and_fpr_fnr[threshold][1] = fnr\n",
    "df_fpr_fnr_thresh = pd.DataFrame.from_dict(dict_of_thresholds_and_fpr_fnr)\n",
    "df_fpr_fnr_thresh.index = ['FPR','FNR']\n",
    "df_fpr_fnr_thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0c84fbeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(DGA)= 0.30063821944681335\n",
      "6ped2nd3yp is not generated by DGA.\n",
      "#####\n",
      "P(DGA)= 0.7272150322721345\n",
      "7fkm2r4pzi is generated by DGA.\n",
      "#####\n",
      "P(DGA)= 0.6655234887504209\n",
      "bzvlwmputpz is generated by DGA.\n",
      "#####\n",
      "P(DGA)= 0.7756749861436567\n",
      "bzvnjpks is generated by DGA.\n",
      "#####\n",
      "P(DGA)= 0.7304263750449718\n",
      "c29kub68m69avkukycwi45hsb68gqctcufybz is generated by DGA.\n",
      "#####\n",
      "P(DGA)= 0.6021101759288413\n",
      "c29nrnuhwjvd60pqk37ate41pynzh64o61atg43 is generated by DGA.\n",
      "#####\n",
      "P(DGA)= 0.6680638244410797\n",
      "c39p22n20ozowiqc59lvnsb18c59dsk17pse31ks is generated by DGA.\n",
      "#####\n",
      "P(DGA)= 0.18927146184009436\n",
      "rediff is not generated by DGA.\n",
      "#####\n",
      "P(DGA)= 0.2525020168396866\n",
      "kaixin001 is not generated by DGA.\n",
      "#####\n",
      "P(DGA)= 0.4524070667116768\n",
      "java is generated by DGA.\n",
      "#####\n",
      "P(DGA)= 0.23960113258288945\n",
      "download is not generated by DGA.\n",
      "#####\n",
      "P(DGA)= 0.17814489660468907\n",
      "google is not generated by DGA.\n",
      "#####\n",
      "P(DGA)= 0.3508064029827192\n",
      "it168 is not generated by DGA.\n",
      "#####\n",
      "P(DGA)= 0.2137127351954888\n",
      "cam4 is not generated by DGA.\n",
      "#####\n",
      "P(DGA)= 0.19242676937441652\n",
      "warriorforum is not generated by DGA.\n",
      "#####\n",
      "P(DGA)= 0.8378843901978125\n",
      "wp is generated by DGA.\n",
      "#####\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Set threshold and classify new data\"\"\"\n",
    "threshold = 0.35\n",
    "df_test = pd.read_csv(test_domains_file, sep=',',header=None)\n",
    "df_test = get_domain_names_without_tld(df_test).drop_duplicates(keep='first')\n",
    "count = 0\n",
    "# Split test domains into substrings\n",
    "for index, row in df_test.iterrows():\n",
    "    sum_scores_dga = 0\n",
    "    sum_scores_non_dga = 0\n",
    "    \n",
    "    for split in n_gram_split:\n",
    "        sub_strs = get_substrings(row[\"domain\"],split)\n",
    "        \n",
    "        # Get scores for substrings from non_dga training dataset\n",
    "        sub_str_scores_non_dga = get_score_from_training_dataset(list_of_counts_of_various_ngrams_non_dga[split],sub_strs)\n",
    "        scores_non_dga = list(sub_str_scores_non_dga.values())\n",
    "        sum_scores_non_dga = sum_scores_non_dga + sum(scores_non_dga)\n",
    "        \n",
    "        # Get scores for substrings from dga training dataset\n",
    "        sub_str_scores_dga = get_score_from_training_dataset(list_of_counts_of_various_ngrams_dga[split],sub_strs)\n",
    "        scores_dga = list(sub_str_scores_dga.values())\n",
    "        sum_scores_dga = sum_scores_dga + sum(scores_dga)\n",
    "    if (sum_scores_dga + sum_scores_non_dga) == 0:\n",
    "        print(row[\"domain\"] + \" origin is uncertain.\")\n",
    "    else:\n",
    "        p_dga = sum_scores_dga/(sum_scores_dga + sum_scores_non_dga)\n",
    "        p_non_dga = sum_scores_non_dga/(sum_scores_non_dga + sum_scores_dga)\n",
    "        print(\"P(DGA)= \"+str(p_dga))\n",
    "#         print(\"P(NON-DGA)= \"+str(p_non_dga))\n",
    "       \n",
    "        if p_dga >= threshold:\n",
    "            print(row[\"domain\"] + \" is generated by DGA.\")\n",
    "        else:\n",
    "            print(row[\"domain\"] + \" is not generated by DGA.\")\n",
    "    print(\"#####\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d54e87",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
